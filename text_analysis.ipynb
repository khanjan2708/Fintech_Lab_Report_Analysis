{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4cb5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "from bs4 import BeautifulSoup\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "551b7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = 'AIzaSyCOUhHFqksZF5X2lILrTzoh0OYfN4J2Pb4'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ca40de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6dabcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.0-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9ed84ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def get_text_from_candidates(response):\n",
    "    \"\"\"Extracts only the text content from the response.candidates list.\n",
    "\n",
    "    Args:\n",
    "      response: The response object from the Gemini API.\n",
    "\n",
    "    Returns:\n",
    "      A list containing the text content from each candidate.\n",
    "    \"\"\"\n",
    "    text_list = []\n",
    "    for candidate in response.candidates:\n",
    "        text_list.append(candidate.content.parts[0].text)  # Access the text part\n",
    "    return text_list\n",
    "\n",
    "def extract_company_info(txt):\n",
    "    # Find the index where HTML starts\n",
    "    html_start_index = txt.find('<HTML>')\n",
    "    \n",
    "    if html_start_index == -1:\n",
    "        raise ValueError(\"HTML not found in the text.\")\n",
    "    \n",
    "    # Split text into two parts: before HTML and HTML part\n",
    "    before_html = txt[:html_start_index]\n",
    "    html_part = txt[html_start_index:]\n",
    "    \n",
    "    # Store the two parts in a list\n",
    "    text_parts = [before_html, html_part]\n",
    "    \n",
    "    # Label the first element as company information text\n",
    "    company_info_text = text_parts[0]\n",
    "    \n",
    "    response = model.generate_content(company_info_text +'\\n' + \"Using the above info Tell me only the name(like ABC) of the company?\" + \"\\n\" \n",
    "                                      + \"When is the filing is filed convert in year-month-day(Answer like Filing Date : 2004-05-10) format(only date nothing else)?\")\n",
    "    \n",
    "    to_markdown(response.text)\n",
    "    text_list = get_text_from_candidates(response)\n",
    "    \n",
    "    answers = []\n",
    "    filing_date = []\n",
    "\n",
    "    # Extract company using regular expression (assuming company name is present)\n",
    "    match = re.search(r\"(?:Company|Company Name): (.*?)\\n\",text_list[0], flags=re.IGNORECASE)  # Case-insensitive\n",
    "    if match:\n",
    "        answers.append(f\"Company: {match.group(1)}\")\n",
    "\n",
    "    # Extract filing date using regular expression\n",
    "    match = re.search(r\"Filing Date : (\\d{4}-\\d{2}-\\d{2})\", text_list[0])\n",
    "    if match:\n",
    "        filing_date.append(match.group(1))\n",
    "# You can add more regular expressions to extract other important information  \n",
    "    \n",
    "    return text_parts, answers, filing_date,text_list\n",
    "\n",
    "file_path = \"sec-edgar-filings/NVDA/10-K/0001012870-02-002262/full-submission.txt\"\n",
    "text = read_txt_file(file_path)\n",
    "\n",
    "text_parts, ans, date,response = extract_company_info(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e2d66901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-K Filing of Company: NVIDIA is filed on 2002-05-14\n"
     ]
    }
   ],
   "source": [
    "print(f\"10-K Filing of {ans[0]} is filed on {date[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c23f2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(text):\n",
    "    \"\"\"Combines a single text string into paragraphs, handling non-breaking spaces and empty lines.\n",
    "\n",
    "    Args:\n",
    "      text: A string containing the text snippets.\n",
    "\n",
    "    Returns:\n",
    "      A string with the combined text, where paragraphs are separated by newlines\n",
    "      and non-breaking spaces are replaced with regular spaces.\n",
    "    \"\"\"\n",
    "\n",
    "    # Process the single text string\n",
    "    processed_text = \"\"\n",
    "    current_paragraph = \"\"\n",
    "    for line in text.splitlines():  # Split text into lines\n",
    "    # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        # Replace non-breaking spaces with regular spaces\n",
    "        line = line.replace(u'\\xa0', ' ')\n",
    "\n",
    "        # Check for triple newlines to mark paragraph breaks\n",
    "        if line == \"\\n\\n\\n\":\n",
    "            if current_paragraph:\n",
    "                processed_text += current_paragraph.strip() + \"\\n\\n\"  # Add paragraph separator with double newlines\n",
    "            current_paragraph = \"\"\n",
    "        else:\n",
    "            current_paragraph += line.strip() + \" \"  # Add text with space for proper separation\n",
    "\n",
    "    # Append the last paragraph (if any)\n",
    "    if current_paragraph:\n",
    "        processed_text += current_paragraph.strip()\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16d5626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse HTML content\n",
    "soup = BeautifulSoup(text_parts[1], 'html.parser')\n",
    "\n",
    "# Extract all text from HTML\n",
    "all_text = soup.get_text()\n",
    "\n",
    "all_text = combine_text(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44de6f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentences = nltk.sent_tokenize(all_text)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e45668c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Prepared by R.R.',\n",
       " 'Donnelley Financial -- Form 10-K UNITED STATES  SECURITIES AND EXCHANGE COMMISSION  Washington, D.C. 20549      FORM 10-K x ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934   For the fiscal year ended January 27, 2002    OR ¨ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934     Commission file number: 0-23985    NVIDIA CORPORATION  (Exact name of registrant as specified in its charter) Delaware 94-3177549 (State or Other Jurisdiction of Incorporation or Organization) (I.R.S.',\n",
       " 'Employer Identification No.)',\n",
       " '2701 San Tomas Expressway  Santa Clara, CA 95050  (408) 486-2000  (Address, including zip code, and telephone number, including area code, of principal executive offices)    Securities registered pursuant to Section 12(b) of the Act:  None    Securities registered pursuant to Section 12(g) of the Act:  Common stock, $.001 par value per share    Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months, and (2) has been subject to such filing requirements for the past 90 days.',\n",
       " 'Yes þ        No ¨    Indicate by check mark if disclosure of delinquent filers pursuant to Item 405 of Regulation S-K is not contained herein and will not be contained, to the best of Registrant’s knowledge, in definitive proxy or information statements incorporated by reference in Part III of this Form 10-K or any amendment to this Form 10-K.    þ    The aggregate market value of the voting stock held by non-affiliates of the registrant as of March 29, 2002 was approximately $4,618,546,324.',\n",
       " 'Shares of common stock held by each current executive officer and director and by each person who is known by the registrant to own 5% or more of the outstanding common stock have been excluded from this computation in that such persons may be deemed to be affiliates of the Company.',\n",
       " 'Share ownership information of certain persons known by the Company to own greater than 5% of the outstanding common stock for purposes of the preceding calculation is based solely on information on Schedule 13G filed with the Commission and is as of March 29, 2002.',\n",
       " 'This determination of affiliate status is not a conclusive determination for other purposes.',\n",
       " 'The number of shares of common stock outstanding as of March 29, 2002 was 151,282,593.',\n",
       " 'DOCUMENTS INCORPORATED BY REFERENCE    The Registrant has incorporated by reference portions of its Proxy Statement for its 2002 Annual Meeting of Stockholders to be filed by May 28, 2002.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74f40817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch, sections, section_dictionary):\n",
    "    \"\"\"Processes a batch of sentences and classifies them into sections.\"\"\"\n",
    "\n",
    "    prompt = f\"Classify the following paragraph:\\n{'. '.join(batch)}\\n\" \\\n",
    "          f\"Possible sections: {' | '.join(sections)}\\n\" \\\n",
    "          f\"If none of the above, classify as 'Other'\"\n",
    "    response = model.generate_content(prompt)\n",
    "\n",
    "    for section_name, classified_sentence in zip(get_text_from_candidates(response), batch):\n",
    "        if section_name in sections:\n",
    "            section_dictionary[section_name].append(classified_sentence)\n",
    "        else:\n",
    "            section_dictionary[\"Others\"].append(classified_sentence)\n",
    "\n",
    "def classify_report_sections(report_text):\n",
    "    \"\"\"Classifies sentences in an annual report into sections using heuristics.\n",
    "\n",
    "    Args:\n",
    "    report_text: A string containing the annual report text.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary where keys are section names and values are lists of sentences in that section.\n",
    "    \"\"\"\n",
    "\n",
    "    sections = [\n",
    "      \"Business\", \"Risk Factors\", \"Selected Financial Data\",\n",
    "      \"Management Discussion\", \"Financial Statements\"\n",
    "    ]\n",
    "    sentences = nltk.sent_tokenize(report_text)\n",
    "    section_dictionary = {section: [] for section in sections}\n",
    "    section_dictionary[\"Others\"] = []\n",
    "\n",
    "    batch_size = 20  # Adjust batch size as needed (consider API limits)\n",
    "    batch = []\n",
    "    for sentence in sentences:\n",
    "        batch.append(sentence)\n",
    "        if len(batch) == batch_size:\n",
    "            process_batch(batch, sections, section_dictionary)\n",
    "            batch = []  # Clear batch after processing\n",
    "\n",
    "    # Process remaining sentences (if any)\n",
    "    if batch:\n",
    "        process_batch(batch, sections, section_dictionary)\n",
    "\n",
    "    return section_dictionary\n",
    "\n",
    "sections_text = classify_report_sections(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70fc648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for section,sentences in sections_text.items():\n",
    "    sections_text[section] = \" \".join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e3e8fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_gemini(text):\n",
    "    \"\"\"\n",
    "    This function calls the Gemini API (replace with your actual API endpoint)\n",
    "    to summarize the text and extract important things it covers.\n",
    "\n",
    "    Args:\n",
    "      text: The text to be summarized.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary containing the summary and important things covered.\n",
    "    \"\"\"\n",
    "    prompt1 = f\"Given text \\n{text} \\n Summarize it\"\n",
    "    prompt2 = f\"Given text \\n{text} \\n Note down important things in New Line and in short\"\n",
    "    summary = model.generate_content(prompt1)\n",
    "    important_things = model.generate_content(prompt2)\n",
    "    \n",
    "    summary = get_text_from_candidates(summary)\n",
    "    important_things = get_text_from_candidates(important_things)\n",
    "    \n",
    "    return summary,important_things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ef2edb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {'Business' : [], 'Financial Statements' : [], 'Management Discussion' : [],\n",
    "           'Risk Factors' : [],'Selected Financial Data' : [],'Others' : []}\n",
    "\n",
    "for section, text in summary.items():\n",
    "    section_text = sections_text[section]\n",
    "    summary_section, imp_of_section = summarize_with_gemini(section_text)\n",
    "    text.append([summary_section,imp_of_section])\n",
    "    \n",
    "    if section == 'Business':\n",
    "        prompt1 = f'From given paragraph : \\n{section_text}\\n What is the main product of the company?'\n",
    "        prompt2 = f'From given paragraph : \\n{section_text}\\n How do they plan to expanding business?'\n",
    "        prompt3 = f'From given paragraph : \\n{section_text}\\n Is the business profitable?'\n",
    "        prompt4 = f'From given paragraph : \\n{section_text}\\n Is there market for it?'\n",
    "        prompt5 = f'From given paragraph : \\n{section_text}\\n How much is the competition in the market for the product?'\n",
    "        \n",
    "        prompt_list = [prompt1,prompt2,prompt3,prompt4,prompt5]\n",
    "        \n",
    "        for prompt in prompt_list:\n",
    "            response1 = model.generate_content(prompt)\n",
    "            text.append(get_text_from_candidates(response1))\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "    elif section == 'Financial Statements':\n",
    "        prompt1 = f'From given paragraph : \\n{section_text}\\n What is the important numbers associated with companies finance here?'\n",
    "        prompt2 = f'From given paragraph : \\n{section_text}\\n How is the result of the companies fincances Good, Moderate, Bad?'\n",
    "        prompt3 = f'From given paragraph : \\n{section_text}\\n Is there growth in investment or Capital Expenditure of Company?'\n",
    "        \n",
    "        prompt_list = [prompt1,prompt2,prompt3]\n",
    "        \n",
    "        for prompt in prompt_list:\n",
    "            response1 = model.generate_content(prompt)\n",
    "            text.append(get_text_from_candidates(response1))\n",
    "            \n",
    "            time.sleep(1)\n",
    "    \n",
    "    else:\n",
    "        prompt1 = f'From given paragraph : \\n{section_text}\\n Give insight of the company work?'\n",
    "        prompt2 = f'From given paragraph : \\n{section_text}\\n Give me small details about management of Company'\n",
    "        prompt3 = f'From given paragraph : \\n{section_text}\\n Give me details of risk associated'\n",
    "        \n",
    "        prompt_list = [prompt1,prompt2,prompt3]\n",
    "        \n",
    "        for prompt in prompt_list:\n",
    "            response1 = model.generate_content(prompt)\n",
    "            text.append(get_text_from_candidates(response1))\n",
    "            \n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef385edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998c22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
